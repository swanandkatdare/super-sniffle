{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xmtJpM7kzTIZ"
   },
   "source": [
    "## Building Basic Models\n",
    "\n",
    "Tensorflow as a toolset is amazing , we are going to be able to build all different architectures and every different field of ML \n",
    "using it, it's terse,steeper learning curve than Keras but it's actually worth it both career wise and power wise .\n",
    "\n",
    "In this notebook we will do a tiny review, build two basic models (regressio, & classification) and take a look at optimizers and other things.\n",
    "\n",
    "\n",
    "Tensorflow is quite an extensive package it can do lots of things and we will use it to build different models using nothing but the ideas we just discussed optimization of loss functions , we are going to build Linear Regression models,LinearSVM  ... and even look at how to implement Nearest Neighbors and others ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zI90nv9R339b"
   },
   "source": [
    "## Linear Regression\n",
    "\n",
    "Linear regression is one of the most important algorithms in statistics. It's used extensively because it simple and highly interpretable , interpretation of results is a very important while deep neural networks are hard to interpret and are similar to a blackbox , statistical models can be interpreted easily , and it is very important to understand how to implement it and its various flavors. . We end up with a number for each feature that directly represents how that feature influences the target or dependent variable.We will introduce how linear regression can be classically implemented, and then move on to how to best implement it in TensorFlow. \n",
    "\n",
    "We start by implementing the simplest linear regression model using mean squared error , we can also use different loss functions such as Ridge (L1) and Lasso (L2) or both (ElasticNet)\n",
    "\n",
    "As an exercice to the reader , you can use the same code but only change the value of the loss function to see how different functions give slightly different results ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lghXZFcVzvbh"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "rng = numpy.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ERyBy7m40yeL"
   },
   "outputs": [],
   "source": [
    "# some random training data\n",
    "# Training Data\n",
    "\"\"\"\n",
    "train_X = numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "train_Y = numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "\"\"\"\n",
    "from sklearn import datasets\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "train_X = np.array(boston.data,dtype=np.float32)\n",
    "train_Y = np.array(boston.target,dtype=np.float32)\n",
    "n_samples = train_X.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "lOd6UnOp2MTR"
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,shape=[None,13],name=\"X\")\n",
    "Y = tf.placeholder(tf.float32,shape=[None,1],name=\"Y\")\n",
    "n_samples = train_X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4gOkhCxVWTf"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fT8XhzAt2WnB"
   },
   "outputs": [],
   "source": [
    "# Å¸ = W*X + b\n",
    "W = tf.Variable(rng.randn(),name='W')\n",
    "b = tf.Variable(rng.randn(),name='b')\n",
    "\n",
    "# Build the linear model\n",
    "Y_hat = W*X + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "H4-6oftz2yz2"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train the model we need an loss function ( a measure of error to optimize) here we construct the MSE (mean squared error)\n",
    "#loss = tf.reduce_mean(tf.square(train_Y-Y_hat))\n",
    "loss = tf.reduce_sum(tf.pow(Y_hat[1]-Y, 2))/(2*n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RAbyuHOK3Qlm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow offers multiple optimizers we pick one (each optimizer has one or multiple parameters that need to be fixed or dynamic)\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vVffDeSg3s_I"
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "training_epochs = 1000\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 479,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1156,
     "status": "error",
     "timestamp": 1518460735406,
     "user": {
      "displayName": "radical rafi",
      "photoUrl": "//lh4.googleusercontent.com/-CSl4WU60pN4/AAAAAAAAAAI/AAAAAAAAAAo/MeadBe2utJQ/s50-c-k-no/photo.jpg",
      "userId": "109128964727701668250"
     },
     "user_tz": 0
    },
    "id": "AT8-3lTI4JBz",
    "outputId": "ccac81a6-5c1a-4ae9-8cfc-6dd1671424c3"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'vstack'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5559bbde24a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'vstack'"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        for (x, y) in zip(train_X, train_Y):\n",
    "            np.vstack(x)\n",
    "            np.vstack(y)\n",
    "            sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "\n",
    "        #Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(loss, feed_dict={X: train_X, Y:train_Y})\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "                \"W=\", sess.run(W), \"b=\", sess.run(b))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    training_cost = sess.run(loss, feed_dict={X: train_X, Y: train_Y})\n",
    "    print(\"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')\n",
    "\n",
    "    #Graphic display\n",
    "    plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pRPO_cbPVWc1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Machine Learning with Tensorflow: Basic Models.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
